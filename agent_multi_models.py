# ===============================================================
# agent_multi_models_v2.1.py ‚Äî Version optimis√©e avec modes d'analyse
# ===============================================================
# Am√©liorations V2.1 :
# 1. Mode d'analyse configurable (Rapide/Normal/D√©taill√©)
# 2. Groupement par chapitre au lieu de section
# 3. Filtrage des sections trop petites
# 4. Estimation du temps avant analyse
# ===============================================================

import os, re, time
from typing import Optional, List, Dict
from datetime import datetime

# ===============================================================
# CONFIGURATION DES APIS
# ===============================================================

# Configuration OpenAI
try:
    from openai import OpenAI, APIError, APITimeoutError
    openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    OPENAI_AVAILABLE = True
except Exception as e:
    print(f"‚ö†Ô∏è OpenAI non disponible : {e}")
    OPENAI_AVAILABLE = False

# Configuration Anthropic (Claude)
try:
    import anthropic
    claude_client = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
    CLAUDE_AVAILABLE = True
except Exception as e:
    print(f"‚ö†Ô∏è Claude non disponible : {e}")
    CLAUDE_AVAILABLE = False

# Configuration Google Gemini
try:
    import google.generativeai as genai
    genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
    gemini_model = genai.GenerativeModel('gemini-1.5-pro')
    GEMINI_AVAILABLE = True
except Exception as e:
    print(f"‚ö†Ô∏è Gemini non disponible : {e}")
    GEMINI_AVAILABLE = False

# ===============================================================
# MODES D'ANALYSE
# ===============================================================

class ModeAnalyse:
    """D√©finit les modes d'analyse disponibles"""
    
    RAPIDE = {
        "nom": "Rapide",
        "description": "Analyse uniquement les chapitres principaux (chapter)",
        "niveaux": ["chapter"],
        "min_mots": 200,
        "duree_estimee": "rapide (5-10 min)"
    }
    
    NORMAL = {
        "nom": "Normal",
        "description": "Analyse les chapitres et sections principales",
        "niveaux": ["chapter", "section"],
        "min_mots": 100,
        "duree_estimee": "moyenne (10-20 min)"
    }
    
    DETAILLE = {
        "nom": "D√©taill√©",
        "description": "Analyse compl√®te : chapitres, sections et sous-sections",
        "niveaux": ["chapter", "section", "subsection"],
        "min_mots": 50,
        "duree_estimee": "longue (20-40 min)"
    }
    
    @staticmethod
    def choisir_mode():
        """Interface pour choisir le mode d'analyse"""
        print("\n" + "="*60)
        print("‚ö° MODE D'ANALYSE")
        print("="*60)
        print("\n[1] üöÄ RAPIDE (5-10 min)")
        print("    ‚Üí Analyse uniquement les chapitres principaux")
        print("    ‚Üí Recommand√© pour : premier aper√ßu, test")
        
        print("\n[2] ‚öñÔ∏è  NORMAL (10-20 min) ‚≠ê RECOMMAND√â")
        print("    ‚Üí Analyse chapitres + sections principales")
        print("    ‚Üí Recommand√© pour : la plupart des documents")
        
        print("\n[3] üî¨ D√âTAILL√â (20-40 min)")
        print("    ‚Üí Analyse compl√®te avec sous-sections")
        print("    ‚Üí Recommand√© pour : th√®ses, documents critiques")
        
        choix = input("\nChoisissez un mode [1-3, d√©faut=2] : ").strip()
        
        if choix == "1":
            return ModeAnalyse.RAPIDE
        elif choix == "3":
            return ModeAnalyse.DETAILLE
        else:
            return ModeAnalyse.NORMAL

# ===============================================================
# CONFIGURATION DES MOD√àLES PAR T√ÇCHE
# ===============================================================

class ConfigModeles:
    """Configuration des mod√®les √† utiliser pour chaque type d'analyse"""
    
    def __init__(self):
        self.modeles = {
            "scientifique": "claude",
            "style": "gemini",
            "plan": "claude",
            "synthese": "claude"
        }
    
    def afficher_config(self):
        """Affiche la configuration actuelle"""
        print("\nüìã Configuration des mod√®les par t√¢che :")
        print(f"  ‚Ä¢ Analyse scientifique : {self.modeles['scientifique'].upper()}")
        print(f"  ‚Ä¢ Am√©lioration style   : {self.modeles['style'].upper()}")
        print(f"  ‚Ä¢ Restructuration plan : {self.modeles['plan'].upper()}")
        print(f"  ‚Ä¢ Synth√®se finale      : {self.modeles['synthese'].upper()}")
    
    def configurer_interactive(self):
        """Configuration interactive des mod√®les"""
        print("\n" + "="*60)
        print("‚öôÔ∏è  CONFIGURATION DES MOD√àLES PAR T√ÇCHE")
        print("="*60)
        print("\nRecommandations :")
        print("  ‚Ä¢ CLAUDE   ‚Üí Meilleur en analyse acad√©mique approfondie")
        print("  ‚Ä¢ GEMINI   ‚Üí Rapide et gratuit, bon pour le style")
        print("  ‚Ä¢ OPENAI   ‚Üí Polyvalent, bon √©quilibre partout")
        print("\nüí° Conseil : Claude pour scientifique/synth√®se, Gemini pour style")
        
        choix = input("\nUtiliser la configuration recommand√©e ? [O/n] : ").strip().lower()
        
        if choix in ['n', 'non', 'no']:
            print("\nüîß Configuration manuelle :")
            taches = {
                "scientifique": "Analyse scientifique (√©quations, coh√©rence)",
                "style": "Am√©lioration stylistique (grammaire, clart√©)",
                "plan": "Restructuration du plan (redondances)",
                "synthese": "Synth√®se finale (rapport global)"
            }
            
            for tache, description in taches.items():
                print(f"\nüìå {description}")
                print("  [1] Claude  [2] Gemini  [3] OpenAI")
                choix_model = input(f"  Mod√®le pour '{tache}' [1-3, d√©faut={self.modeles[tache]}] : ").strip()
                
                if choix_model == '1':
                    self.modeles[tache] = 'claude'
                elif choix_model == '2':
                    self.modeles[tache] = 'gemini'
                elif choix_model == '3':
                    self.modeles[tache] = 'openai'
        
        print("\n‚úÖ Configuration finalis√©e !")
        self.afficher_config()

# ===============================================================
# GESTION DES DOSSIERS DE SORTIE
# ===============================================================

class GestionnaireDossiers:
    """G√®re l'organisation des fichiers de sortie"""
    
    def __init__(self, nom_fichier_source: str, mode: Dict):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        nom_base = os.path.splitext(os.path.basename(nom_fichier_source))[0]
        mode_nom = mode["nom"].lower()
        self.dossier_principal = f"analyse_{nom_base}_{mode_nom}_{timestamp}"
        
        self.dossier_syntheses = os.path.join(self.dossier_principal, "syntheses_chapitres")
        self.dossier_rapports = os.path.join(self.dossier_principal, "rapports")
        self.dossier_logs = os.path.join(self.dossier_principal, "logs")
        
        self.creer_structure()
    
    def creer_structure(self):
        """Cr√©e la structure de dossiers"""
        os.makedirs(self.dossier_principal, exist_ok=True)
        os.makedirs(self.dossier_syntheses, exist_ok=True)
        os.makedirs(self.dossier_rapports, exist_ok=True)
        os.makedirs(self.dossier_logs, exist_ok=True)
        
        print(f"\nüìÅ Dossier d'analyse cr√©√© : {self.dossier_principal}/")
    
    def chemin_synthese(self, numero: int, config: ConfigModeles) -> str:
        modeles_str = f"{config.modeles['scientifique']}-{config.modeles['style']}"
        return os.path.join(self.dossier_syntheses, f"chapitre_{numero:02d}_{modeles_str}.txt")
    
    def chemin_rapport(self, config: ConfigModeles) -> str:
        modele_principal = config.modeles['synthese']
        return os.path.join(self.dossier_rapports, f"rapport_analyse_{modele_principal}.tex")
    
    def chemin_log(self) -> str:
        return os.path.join(self.dossier_logs, "analyse.log")
    
    def chemin_config(self) -> str:
        return os.path.join(self.dossier_principal, "configuration.txt")
    
    def sauvegarder_config(self, config: ConfigModeles, fichier_source: str, mode: Dict, nb_sections: int):
        """Sauvegarde la configuration utilis√©e"""
        with open(self.chemin_config(), "w", encoding="utf-8") as f:
            f.write("="*60 + "\n")
            f.write("CONFIGURATION DE L'ANALYSE\n")
            f.write("="*60 + "\n\n")
            f.write(f"Date/Heure : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Fichier source : {fichier_source}\n")
            f.write(f"Mode d'analyse : {mode['nom']} ({mode['duree_estimee']})\n")
            f.write(f"Sections analys√©es : {nb_sections}\n\n")
            f.write("Mod√®les utilis√©s par t√¢che :\n")
            for tache, modele in config.modeles.items():
                f.write(f"  ‚Ä¢ {tache.capitalize():20s} : {modele.upper()}\n")
            f.write("\nNiveaux de structure analys√©s :\n")
            for niveau in mode['niveaux']:
                f.write(f"  ‚Ä¢ {niveau}\n")
            f.write(f"\nMot minimum par section : {mode['min_mots']}\n")
            f.write("\n" + "="*60 + "\n")

# ===============================================================
# WRAPPER UNIFI√â POUR LES 3 APIS
# ===============================================================

def safe_call_unified(system_prompt: str, user_prompt: str, temperature: float = 0.3, model: str = "claude") -> Optional[str]:
    """Appel unifi√© pour Claude, Gemini ou OpenAI avec retry"""
    
    for attempt in range(3):
        try:
            if model == "claude" and CLAUDE_AVAILABLE:
                response = claude_client.messages.create(
                    model="claude-sonnet-4-20250514",
                    max_tokens=4000,
                    temperature=temperature,
                    system=system_prompt,
                    messages=[{"role": "user", "content": user_prompt}]
                )
                return response.content[0].text
            
            elif model == "gemini" and GEMINI_AVAILABLE:
                full_prompt = f"{system_prompt}\n\n{user_prompt}"
                response = gemini_model.generate_content(
                    full_prompt,
                    generation_config=genai.types.GenerationConfig(
                        temperature=temperature,
                        max_output_tokens=4000
                    )
                )
                return response.text
            
            elif model == "openai" and OPENAI_AVAILABLE:
                response = openai_client.chat.completions.create(
                    model="gpt-4o",
                    temperature=temperature,
                    max_tokens=4000,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ]
                )
                return response.choices[0].message.content
            
            else:
                print(f"‚ùå Mod√®le '{model}' non disponible ou non configur√©.")
                return None
                
        except Exception as e:
            print(f"‚ö†Ô∏è Tentative {attempt+1}/3 √©chou√©e ({type(e).__name__}): {str(e)[:100]}")
            time.sleep(5)
    
    print("‚ùå Abandon apr√®s 3 tentatives.")
    return None

# ===============================================================
# AGENTS SP√âCIALIS√âS
# ===============================================================

def agent_scientifique(section_text: str, model: str = "claude") -> str:
    """Agent 1Ô∏è‚É£ ‚Äî Analyse scientifique et math√©matique"""
    system = "Tu es un expert en math√©matiques appliqu√©es et mod√©lisation num√©rique."
    prompt = f"""
Analyse scientifique d'un m√©moire en math√©matiques appliqu√©es :
- V√©rifie la coh√©rence th√©orique et la rigueur math√©matique.
- Identifie les erreurs symboliques, incoh√©rences, omissions.
- Sugg√®re des am√©liorations pr√©cises et reformulations.

Texte :
{section_text[:4000]}
"""
    result = safe_call_unified(system, prompt, temperature=0.2, model=model)
    return result or "Analyse scientifique non disponible."

def agent_style(section_text: str, model: str = "gemini") -> str:
    """Agent 2Ô∏è‚É£ ‚Äî Style acad√©mique et r√©dactionnel"""
    system = "Tu es un relecteur acad√©mique sp√©cialis√© dans la r√©daction scientifique."
    prompt = f"""
Am√©liore le style acad√©mique du texte suivant :
- Corrige grammaire, syntaxe, ponctuation et style scientifique.
- Supprime les redondances et lourdeurs.
- Clarifie les phrases trop longues.

Texte :
{section_text[:4000]}
"""
    result = safe_call_unified(system, prompt, temperature=0.4, model=model)
    return result or "Am√©lioration stylistique non disponible."

def agent_plan(plan_text: str, model: str = "claude") -> str:
    """Agent 3Ô∏è‚É£ ‚Äî Structure et organisation du document"""
    system = "Tu es un rapporteur de th√®se sp√©cialis√© dans la structuration acad√©mique."
    prompt = f"""
Analyse la structure du m√©moire :
- D√©tecte les redondances entre sections.
- Propose un plan restructur√© complet (chapitres, sections, sous-sections).
- Indique les fusions, suppressions et int√©grations √† pr√©voir.
- Sugg√®re un nombre de pages par section.

Plan d√©tect√© :
{plan_text[:4000]}
"""
    result = safe_call_unified(system, prompt, temperature=0.3, model=model)
    return result or "Analyse du plan non disponible."

def agent_synthese(chapitre: str, analyses: list, model: str = "claude") -> str:
    """Agent 4Ô∏è‚É£ ‚Äî Synth√®se globale par chapitre"""
    system = "Tu es un examinateur scientifique r√©digeant un rapport de synth√®se."
    joined = "\n\n".join(analyses)
    prompt = f"""
R√©dige une synth√®se critique compl√®te du chapitre intitul√© ¬´ {chapitre} ¬ª :
- R√©sume les points forts et faiblesses scientifiques et r√©dactionnels.
- Int√®gre les remarques de fond, de forme et de structure.
- Propose des reformulations et des suggestions concr√®tes.
- Pr√©sente le tout en paragraphes structur√©s et fluides (2 √† 3 pages √©quivalentes).

Analyses des agents pr√©c√©dents :
{joined[:8000]}
"""
    result = safe_call_unified(system, prompt, temperature=0.4, model=model)
    return result or "Synth√®se non disponible."

# ===============================================================
# UTILITAIRES LATEX - VERSION AM√âLIOR√âE
# ===============================================================

def lire_latex(fichier: str) -> str:
    """Lit un fichier LaTeX"""
    with open(fichier, "r", encoding="utf-8") as f:
        return f.read()

def compter_mots(texte: str) -> int:
    """Compte le nombre de mots dans un texte"""
    # Enl√®ve les commandes LaTeX pour un compte plus pr√©cis
    texte_nettoye = re.sub(r'\\[a-zA-Z]+\{[^}]*\}', '', texte)
    texte_nettoye = re.sub(r'\\[a-zA-Z]+', '', texte_nettoye)
    mots = texte_nettoye.split()
    return len(mots)

def extraire_chapitres_optimise(contenu: str, mode: Dict) -> List[Dict]:
    """
    Extrait les chapitres/sections selon le mode choisi
    Groupe les sous-sections avec leur section parente
    """
    # Extraction de toutes les structures
    pattern = re.compile(r'\\(chapter|section|subsection)\{([^}]*)\}')
    positions = [(m.start(), m.group(1), m.group(2)) for m in pattern.finditer(contenu)]
    
    niveaux_autorises = mode['niveaux']
    min_mots = mode['min_mots']
    
    chapitres = []
    
    i = 0
    while i < len(positions):
        pos, niveau, titre = positions[i]
        
        # Si ce niveau n'est pas autoris√©, on skip
        if niveau not in niveaux_autorises:
            i += 1
            continue
        
        # Trouver la fin de cette section
        start = pos
        end = len(contenu)
        
        # Chercher la prochaine section de m√™me niveau ou sup√©rieur
        for j in range(i + 1, len(positions)):
            next_pos, next_niveau, _ = positions[j]
            
            # Hi√©rarchie : chapter > section > subsection
            niveau_hierarchie = {"chapter": 1, "section": 2, "subsection": 3}
            
            if niveau_hierarchie[next_niveau] <= niveau_hierarchie[niveau]:
                end = next_pos
                break
        
        texte = contenu[start:end]
        nb_mots = compter_mots(texte)
        
        # Filtrer les sections trop petites
        if nb_mots >= min_mots:
            chapitres.append({
                "type": niveau,
                "titre": titre.strip(),
                "texte": texte,
                "nb_mots": nb_mots
            })
        
        i += 1
    
    return chapitres

def estimer_duree(nb_sections: int, config: ConfigModeles) -> str:
    """Estime la dur√©e de l'analyse"""
    # Estimation: ~1-2 min par section en moyenne
    duree_min = nb_sections * 1
    duree_max = nb_sections * 2
    return f"{duree_min}-{duree_max} minutes"

def ecrire_rapport_latex(chapitres: list, syntheses: list, plan_restructure: str, 
                         dossiers: GestionnaireDossiers, config: ConfigModeles, mode: Dict):
    """G√©n√®re le rapport final en LaTeX"""
    chemin_rapport = dossiers.chemin_rapport(config)
    
    with open(chemin_rapport, "w", encoding="utf-8") as f:
        f.write(r"""\documentclass[12pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage{geometry}
\usepackage{xcolor}
\geometry{margin=2.5cm}
\begin{document}
\title{Rapport d'analyse multi-agent}
\author{G√©n√©r√© par IA multi-mod√®les}
\date{\today}
\maketitle

\section*{Configuration utilis√©e}
""")
        f.write(f"Mode d'analyse : {mode['nom']}\n\n")
        f.write("Mod√®les IA par t√¢che :\n\\begin{itemize}\n")
        for tache, modele in config.modeles.items():
            f.write(f"\\item {tache.capitalize()} : {modele.upper()}\n")
        f.write("\\end{itemize}\n\n")
        
        f.write(r"\tableofcontents" + "\n\\newpage\n")
        f.write(r"\chapter*{Rapport global d'analyse du m√©moire}" + "\n")
        
        for ch, syn in zip(chapitres, syntheses):
            f.write(f"\\section*{{{ch['titre']} ({ch['nb_mots']} mots)}}\n")
            texte_escape = syn.replace("_", "\\_").replace("%", "\\%").replace("&", "\\&").replace("#", "\\#")
            f.write(texte_escape + "\n\n")
        
        f.write(r"\chapter*{Proposition de plan restructur√©}" + "\n")
        plan_escape = plan_restructure.replace("_", "\\_").replace("%", "\\%").replace("&", "\\&").replace("#", "\\#")
        f.write(plan_escape + "\n\n")
        f.write(r"\end{document}")
    
    print(f"‚úÖ Rapport LaTeX : {chemin_rapport}")

# ===============================================================
# LOGGER
# ===============================================================

class Logger:
    """Enregistre les √©tapes de l'analyse"""
    
    def __init__(self, chemin: str):
        self.chemin = chemin
        self.debut = time.time()
        with open(self.chemin, "w", encoding="utf-8") as f:
            f.write("="*60 + "\n")
            f.write("LOG D'ANALYSE MULTI-AGENT\n")
            f.write("="*60 + "\n\n")
            f.write(f"D√©but : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
    
    def log(self, message: str):
        """Ajoute une entr√©e au log"""
        with open(self.chemin, "a", encoding="utf-8") as f:
            timestamp = datetime.now().strftime("%H:%M:%S")
            f.write(f"[{timestamp}] {message}\n")
    
    def fin(self):
        """Marque la fin de l'analyse"""
        duree = time.time() - self.debut
        with open(self.chemin, "a", encoding="utf-8") as f:
            f.write(f"\nFin : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Dur√©e totale : {duree:.1f} secondes ({duree/60:.1f} minutes)\n")

# ===============================================================
# ORCHESTRATION PRINCIPALE
# ===============================================================

if __name__ == "__main__":
    print("=" * 60)
    print("ü§ñ ANALYSEUR MULTI-AGENT IA - VERSION 2.1 OPTIMIS√âE")
    print("=" * 60)
    print("\n‚ú® Nouveaut√©s V2.1 :")
    print("  ‚Ä¢ Modes d'analyse (Rapide/Normal/D√©taill√©)")
    print("  ‚Ä¢ Groupement par chapitre")
    print("  ‚Ä¢ Filtrage sections courtes")
    print("  ‚Ä¢ Estimation du temps")
    
    # Choix du mode d'analyse
    mode = ModeAnalyse.choisir_mode()
    print(f"\n‚úÖ Mode s√©lectionn√© : {mode['nom']}")
    print(f"   Dur√©e estim√©e : {mode['duree_estimee']}")
    
    # Configuration des mod√®les
    config = ConfigModeles()
    config.configurer_interactive()
    
    # Lecture du fichier
    print("\n" + "="*60)
    fichier = input("üìÑ Nom du fichier .tex √† analyser : ").strip()
    if not os.path.exists(fichier):
        print(f"‚ùå Fichier '{fichier}' introuvable.")
        exit(1)
    
    # Extraction optimis√©e
    contenu = lire_latex(fichier)
    chapitres = extraire_chapitres_optimise(contenu, mode)
    
    # Affichage du r√©sum√©
    print(f"\nüìä R√©sum√© de l'analyse :")
    print(f"   ‚Ä¢ Mode : {mode['nom']}")
    print(f"   ‚Ä¢ Sections √† analyser : {len(chapitres)}")
    total_mots = sum(ch['nb_mots'] for ch in chapitres)
    print(f"   ‚Ä¢ Mots totaux : {total_mots:,}")
    print(f"   ‚Ä¢ Dur√©e estim√©e : {estimer_duree(len(chapitres), config)}")
    
    # Confirmation
    continuer = input("\nContinuer avec cette analyse ? [O/n] : ").strip().lower()
    if continuer in ['n', 'non', 'no']:
        print("‚ùå Analyse annul√©e.")
        exit(0)
    
    # Cr√©ation de la structure de dossiers
    dossiers = GestionnaireDossiers(fichier, mode)
    dossiers.sauvegarder_config(config, fichier, mode, len(chapitres))
    
    # Initialisation du logger
    logger = Logger(dossiers.chemin_log())
    logger.log(f"Analyse du fichier : {fichier}")
    logger.log(f"Mode : {mode['nom']}, {len(chapitres)} sections")
    
    # Analyse du plan global
    print("\nüß≠ G√©n√©ration du plan restructur√© global...")
    plan_text = "\n".join([f"{c['type']}: {c['titre']} ({c['nb_mots']} mots)" for c in chapitres])
    logger.log(f"Analyse du plan avec {config.modeles['plan'].upper()}")
    plan_restructure = agent_plan(plan_text, model=config.modeles['plan'])
    
    # Analyse chapitre par chapitre
    syntheses = []
    temps_debut_analyse = time.time()
    
    for i, ch in enumerate(chapitres, 1):
        temps_debut_section = time.time()
        print(f"\nüîé Analyse {i}/{len(chapitres)} : {ch['titre'][:60]}... ({ch['nb_mots']} mots)")
        logger.log(f"D√©but analyse chapitre {i}: {ch['titre']}")
        
        print(f"   ‚Üí Agent scientifique ({config.modeles['scientifique'].upper()})...")
        sci = agent_scientifique(ch["texte"], model=config.modeles['scientifique'])
        
        print(f"   ‚Üí Agent stylistique ({config.modeles['style'].upper()})...")
        sty = agent_style(ch["texte"], model=config.modeles['style'])
        
        print(f"   ‚Üí Synth√®se finale ({config.modeles['synthese'].upper()})...")
        syn = agent_synthese(ch["titre"], [sci, sty], model=config.modeles['synthese'])
        syntheses.append(syn)
        
        # Sauvegarde individuelle
        chemin_synthese = dossiers.chemin_synthese(i, config)
        with open(chemin_synthese, "w", encoding="utf-8") as f:
            f.write(f"{'='*60}\n")
            f.write(f"CHAPITRE {i} : {ch['titre']}\n")
            f.write(f"Type : {ch['type']} | Mots : {ch['nb_mots']}\n")
            f.write(f"{'='*60}\n\n")
            f.write(f"--- ANALYSE SCIENTIFIQUE ({config.modeles['scientifique'].upper()}) ---\n{sci}\n\n")
            f.write(f"--- ANALYSE STYLISTIQUE ({config.modeles['style'].upper()}) ---\n{sty}\n\n")
            f.write(f"--- SYNTH√àSE FINALE ({config.modeles['synthese'].upper()}) ---\n{syn}\n")
        
        temps_fin_section = time.time()
        duree_section = temps_fin_section - temps_debut_section
        temps_restant = (len(chapitres) - i) * duree_section
        
        print(f"   ‚úÖ Sauvegard√© ({duree_section:.1f}s) | Temps restant estim√©: {temps_restant/60:.1f} min")
        logger.log(f"Chapitre {i} termin√© en {duree_section:.1f}s")
    
    # G√©n√©ration du rapport final
    print("\nüìù G√©n√©ration du rapport final...")
    ecrire_rapport_latex(chapitres, syntheses, plan_restructure, dossiers, config, mode)
    logger.log("Rapport LaTeX g√©n√©r√©")
    
    # Statistiques finales
    temps_total = time.time() - temps_debut_analyse
    logger.fin()
    
    print("\n" + "=" * 60)
    print("üèÅ ANALYSE TERMIN√âE AVEC SUCC√àS !")
    print("=" * 60)
    print(f"\n‚è±Ô∏è  Statistiques :")
    print(f"   ‚Ä¢ Sections analys√©es : {len(chapitres)}")
    print(f"   ‚Ä¢ Temps total : {temps_total/60:.1f} minutes")
    print(f"   ‚Ä¢ Temps moyen/section : {temps_total/len(chapitres):.1f} secondes")
    print(f"\nüìÅ Tous les fichiers sont dans : {dossiers.dossier_principal}/")
    print(f"\nüí° Conseil : Consultez 'configuration.txt' pour voir les d√©tails")